#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞–∫–∫—É—Ä–∞—Ç–Ω—ã—Ö CSV/Parquet –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –æ—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –≤–Ω–µ—à–Ω–∏—Ö —Å–∏—Å—Ç–µ–º–∞—Ö –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
"""

import pandas as pd
import psycopg2
import pyarrow as pa
import pyarrow.parquet as pq
import os
import json
from datetime import datetime, timedelta
from pathlib import Path
from dotenv import load_dotenv
import logging

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('data_export.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

class DataExporter:
    def __init__(self, output_dir='exported_data'):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"""
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–æ–∫ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
        (self.output_dir / 'csv').mkdir(exist_ok=True)
        (self.output_dir / 'parquet').mkdir(exist_ok=True)
        (self.output_dir / 'json').mkdir(exist_ok=True)
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ë–î
        self.db_config = {
            'host': os.getenv('DB_HOST', '103.246.146.132'),
            'port': os.getenv('DB_PORT', 5432),
            'database': os.getenv('DB_NAME', 'hackathon'),
            'user': os.getenv('DB_USER', 'user_db'),
            'password': os.getenv('DB_PASSWORD', 'psql14182025')
        }
        
        self.export_manifest = {
            'export_timestamp': datetime.now().isoformat(),
            'exported_tables': [],
            'file_sizes': {},
            'record_counts': {},
            'data_quality_summary': {}
        }
        
    def connect_db(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            self.conn = psycopg2.connect(**self.db_config)
            logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
            return False
            
    def execute_query(self, query, params=None):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ SQL –∑–∞–ø—Ä–æ—Å–∞ —Å –≤–æ–∑–≤—Ä–∞—Ç–æ–º DataFrame"""
        try:
            return pd.read_sql(query, self.conn, params=params)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return None
            
    def export_table_to_formats(self, table_name, query, description=""):
        """–≠–∫—Å–ø–æ—Ä—Ç —Ç–∞–±–ª–∏—Ü—ã –≤ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã"""
        logger.info(f"üìä –≠–∫—Å–ø–æ—Ä—Ç —Ç–∞–±–ª–∏—Ü—ã: {table_name}")
        
        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
        df = self.execute_query(query)
        if df is None or df.empty:
            logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞: {table_name}")
            return False
            
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ —Å timestamp
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        base_filename = f"{table_name}_{timestamp}"
        
        # –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV
        csv_path = self.output_dir / 'csv' / f"{base_filename}.csv"
        df.to_csv(csv_path, index=False, encoding='utf-8')
        logger.info(f"üìÑ CSV —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {csv_path}")
        
        # –≠–∫—Å–ø–æ—Ä—Ç –≤ Parquet
        parquet_path = self.output_dir / 'parquet' / f"{base_filename}.parquet"
        df.to_parquet(parquet_path, index=False, engine='pyarrow', compression='snappy')\n        logger.info(f"üì¶ Parquet —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {parquet_path}")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        metadata = {
            'table_name': table_name,
            'description': description,
            'export_timestamp': datetime.now().isoformat(),
            'record_count': len(df),
            'column_count': len(df.columns),
            'columns': [
                {
                    'name': col,
                    'dtype': str(df[col].dtype),
                    'null_count': int(df[col].isnull().sum()),
                    'unique_count': int(df[col].nunique())
                }
                for col in df.columns
            ],
            'data_types': dict(df.dtypes.astype(str)),
            'sample_data': df.head(3).to_dict('records') if len(df) > 0 else [],
            'file_sizes': {
                'csv_mb': round(csv_path.stat().st_size / 1024 / 1024, 2),
                'parquet_mb': round(parquet_path.stat().st_size / 1024 / 1024, 2)
            }
        }
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ JSON
        metadata_path = self.output_dir / 'json' / f"{base_filename}_metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2, default=str)
        logger.info(f"üìã –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metadata_path}")
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–∞–Ω–∏—Ñ–µ—Å—Ç–∞
        self.export_manifest['exported_tables'].append(table_name)
        self.export_manifest['record_counts'][table_name] = len(df)
        self.export_manifest['file_sizes'][table_name] = metadata['file_sizes']
        
        logger.info(f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω: {table_name} ({len(df):,} –∑–∞–ø–∏—Å–µ–π)")
        return True
        
    def export_customers_data(self):
        """–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π"""
        query = """
        WITH customer_metrics AS (
            SELECT 
                c.id,
                c.name,
                c.email,
                c.phone,
                c.company_name,
                c.industry,
                c.status,
                c.registration_date,
                c.last_login,
                c.created_at,
                c.updated_at,
                
                -- –ú–µ—Ç—Ä–∏–∫–∏ –∑–∞–∫–∞–∑–æ–≤
                COALESCE(om.total_orders, 0) as total_orders,
                COALESCE(om.paid_orders, 0) as paid_orders,
                COALESCE(om.total_spent, 0) as total_spent,
                COALESCE(om.avg_order_value, 0) as avg_order_value,
                om.first_order_date,
                om.last_order_date,
                
                -- –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
                CASE 
                    WHEN COALESCE(om.total_spent, 0) > 50000 THEN 'VIP'
                    WHEN COALESCE(om.total_spent, 0) > 20000 THEN 'Premium'
                    WHEN COALESCE(om.total_spent, 0) > 5000 THEN 'Regular'
                    WHEN COALESCE(om.total_orders, 0) > 0 THEN 'Occasional'
                    ELSE 'New'
                END as customer_segment,
                
                -- –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
                CASE 
                    WHEN om.last_order_date IS NULL THEN 'no_orders'
                    WHEN DATE_PART('day', CURRENT_DATE - om.last_order_date) <= 30 THEN 'active'
                    WHEN DATE_PART('day', CURRENT_DATE - om.last_order_date) <= 90 THEN 'dormant'
                    ELSE 'inactive'
                END as activity_status,
                
                -- –¢–∏–ø –∫–ª–∏–µ–Ω—Ç–∞
                CASE 
                    WHEN c.company_name IS NOT NULL AND c.company_name != '' THEN 'B2B'
                    ELSE 'B2C'
                END as customer_type,
                
                -- –í–æ–∑—Ä–∞—Å—Ç –∫–ª–∏–µ–Ω—Ç–∞ –≤ –¥–Ω—è—Ö
                DATE_PART('day', CURRENT_DATE - c.registration_date) as customer_age_days
                
            FROM customers c
            LEFT JOIN (
                SELECT 
                    customer_id,
                    COUNT(*) as total_orders,
                    COUNT(CASE WHEN payment_status = 'paid' THEN 1 END) as paid_orders,
                    SUM(CASE WHEN payment_status = 'paid' THEN 
                        (SELECT SUM(oi.quantity * oi.unit_price) 
                         FROM order_items oi 
                         WHERE oi.order_id = o.id)
                    ELSE 0 END) as total_spent,
                    AVG(CASE WHEN payment_status = 'paid' THEN 
                        (SELECT SUM(oi.quantity * oi.unit_price) 
                         FROM order_items oi 
                         WHERE oi.order_id = o.id)
                    END) as avg_order_value,
                    MIN(order_date) as first_order_date,
                    MAX(order_date) as last_order_date
                FROM orders o
                GROUP BY customer_id
            ) om ON c.id = om.customer_id
        )
        SELECT * FROM customer_metrics
        ORDER BY total_spent DESC, registration_date DESC
        """
        
        return self.export_table_to_formats(
            'customers_analytics',
            query,
            '–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç–æ–≤ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∑–∞–∫–∞–∑–æ–≤, —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π –∏ —Å—Ç–∞—Ç—É—Å–æ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏'
        )
        
    def export_orders_data(self):
        """–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞–∫–∞–∑–æ–≤ —Å —Ä–∞—Å—á–µ—Ç–Ω—ã–º–∏ –ø–æ–ª—è–º–∏"""
        query = """
        WITH order_details AS (
            SELECT 
                o.id,
                o.customer_id,
                o.order_date,
                o.status,
                o.payment_status,
                o.shipping_address,
                o.created_at,
                o.updated_at,
                
                -- –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–ª–∏–µ–Ω—Ç–µ
                c.name as customer_name,
                c.email as customer_email,
                c.company_name,
                CASE 
                    WHEN c.company_name IS NOT NULL AND c.company_name != '' THEN 'B2B'
                    ELSE 'B2C'
                END as customer_type,
                
                -- –†–∞—Å—á–µ—Ç–Ω—ã–µ –ø–æ–ª—è –∑–∞–∫–∞–∑–∞
                COALESCE(oi.total_amount, 0) as total_amount,
                COALESCE(oi.items_count, 0) as items_count,
                COALESCE(oi.total_quantity, 0) as total_quantity,
                
                -- –°—Ç–∞—Ç—É—Å—ã
                CASE WHEN o.payment_status = 'paid' THEN oi.total_amount ELSE 0 END as paid_amount,
                CASE WHEN o.status = 'delivered' THEN 1 ELSE 0 END as is_delivered,
                CASE WHEN o.status = 'cancelled' THEN 1 ELSE 0 END as is_cancelled,
                CASE WHEN o.status = 'returned' THEN 1 ELSE 0 END as is_returned,
                
                -- –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                EXTRACT(YEAR FROM o.order_date) as order_year,
                EXTRACT(MONTH FROM o.order_date) as order_month,
                EXTRACT(DOW FROM o.order_date) as order_dow,
                EXTRACT(HOUR FROM o.created_at) as order_hour,
                
                -- –†–µ–≥–∏–æ–Ω–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                CASE 
                    WHEN o.shipping_address LIKE '%–ú–æ—Å–∫–≤–∞%' OR o.shipping_address LIKE '%Moscow%' THEN '–ú–æ—Å–∫–≤–∞'
                    WHEN o.shipping_address LIKE '%–°–∞–Ω–∫—Ç-–ü–µ—Ç–µÔøΩÔøΩ–±—É—Ä–≥%' OR o.shipping_address LIKE '%–°–ü–±%' THEN '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥'
                    WHEN o.shipping_address LIKE '%–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥%' THEN '–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥'
                    WHEN o.shipping_address LIKE '%–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫%' THEN '–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫'
                    ELSE '–î—Ä—É–≥–∏–µ —Ä–µ–≥–∏–æ–Ω—ã'
                END as region,
                
                -- –ö–∞–Ω–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                CASE 
                    WHEN EXTRACT(HOUR FROM o.created_at) BETWEEN 9 AND 18 THEN '–†–∞–±–æ—á–∏–µ —á–∞—Å—ã'
                    WHEN EXTRACT(HOUR FROM o.created_at) BETWEEN 19 AND 23 THEN '–í–µ—á–µ—Ä–Ω–µ–µ –≤—Ä–µ–º—è'
                    ELSE '–ù–æ—á–Ω–æ–µ –≤—Ä–µ–º—è'
                END as time_channel,
                
                CASE 
                    WHEN EXTRACT(DOW FROM o.order_date) IN (1,2,3,4,5) THEN '–ë—É–¥–Ω–∏'
                    ELSE '–í—ã—Ö–æ–¥–Ω—ã–µ'
                END as day_type
                
            FROM orders o
            LEFT JOIN customers c ON o.customer_id = c.id
            LEFT JOIN (
                SELECT 
                    order_id,
                    SUM(quantity * unit_price) as total_amount,
                    COUNT(*) as items_count,
                    SUM(quantity) as total_quantity
                FROM order_items
                GROUP BY order_id
            ) oi ON o.id = oi.order_id
        )
        SELECT * FROM order_details
        ORDER BY order_date DESC, id DESC
        """
        
        return self.export_table_to_formats(
            'orders_analytics',
            query,
            '–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–∫–∞–∑–æ–≤ —Å —Ä–∞—Å—á–µ—Ç–Ω—ã–º–∏ –ø–æ–ª—è–º–∏, —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω–æ–π –∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä–∞–∑–±–∏–≤–∫–æ–π'
        )
        
    def export_products_data(self):
        """–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –ø—Ä–æ–¥–∞–∂"""
        query = """
        WITH product_analytics AS (
            SELECT 
                p.id,
                p.name,
                p.description,
                p.category,
                p.supplier_id,
                p.purchase_price,
                p.selling_price,
                p.stock_quantity,
                p.reorder_level,
                p.is_active,
                p.created_at,
                p.updated_at,
                
                -- –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–¥–∞–∂
                COALESCE(pm.total_sold, 0) as total_sold,
                COALESCE(pm.total_revenue, 0) as total_revenue,
                COALESCE(pm.order_count, 0) as order_count,
                pm.last_sale_date,
                pm.first_sale_date,
                
                -- –†–∞—Å—á–µ—Ç–Ω—ã–µ –ø–æ–ª—è
                ROUND(p.selling_price - p.purchase_price, 2) as profit_per_unit,
                ROUND((p.selling_price - p.purchase_price) * COALESCE(pm.total_sold, 0), 2) as total_profit,
                ROUND(p.stock_quantity * p.purchase_price, 2) as inventory_value,
                
                -- –ú–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å
                CASE 
                    WHEN p.purchase_price > 0 
                    THEN ROUND((p.selling_price - p.purchase_price) / p.purchase_price * 100, 2)
                    ELSE 0 
                END as profit_margin_percent,
                
                -- –°—Ç–∞—Ç—É—Å –∑–∞–ø–∞—Å–æ–≤
                CASE 
                    WHEN p.stock_quantity <= p.reorder_level THEN 'low_stock'
                    WHEN p.stock_quantity = 0 THEN 'out_of_stock'
                    ELSE 'in_stock'
                END as stock_status,
                
                -- –ü–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å
                CASE 
                    WHEN COALESCE(pm.total_sold, 0) > 100 THEN 'high_demand'
                    WHEN COALESCE(pm.total_sold, 0) > 10 THEN 'medium_demand'
                    WHEN COALESCE(pm.total_sold, 0) > 0 THEN 'low_demand'
                    ELSE 'no_sales'
                END as demand_level,
                
                -- –î–Ω–∏ —Å –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø—Ä–æ–¥–∞–∂–∏
                CASE 
                    WHEN pm.last_sale_date IS NOT NULL 
                    THEN DATE_PART('day', CURRENT_DATE - pm.last_sale_date)
                    ELSE NULL
                END as days_since_last_sale,
                
                -- ABC –∞–Ω–∞–ª–∏–∑ –ø–æ –≤—ã—Ä—É—á–∫–µ
                CASE 
                    WHEN COALESCE(pm.total_revenue, 0) > 100000 THEN 'A'
                    WHEN COALESCE(pm.total_revenue, 0) > 10000 THEN 'B'
                    WHEN COALESCE(pm.total_revenue, 0) > 0 THEN 'C'
                    ELSE 'N'
                END as abc_category
                
            FROM products p
            LEFT JOIN (
                SELECT 
                    oi.product_id,
                    SUM(oi.quantity) as total_sold,
                    SUM(oi.quantity * oi.unit_price) as total_revenue,
                    COUNT(DISTINCT oi.order_id) as order_count,
                    MIN(o.order_date) as first_sale_date,
                    MAX(o.order_date) as last_sale_date
                FROM order_items oi
                JOIN orders o ON oi.order_id = o.id
                WHERE o.payment_status = 'paid'
                GROUP BY oi.product_id
            ) pm ON p.id = pm.product_id
        )
        SELECT * FROM product_analytics
        ORDER BY total_revenue DESC, total_sold DESC
        """
        
        return self.export_table_to_formats(
            'products_analytics',
            query,
            '–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä–æ–≤ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –ø—Ä–æ–¥–∞–∂, —Ä–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å—é –∏ ABC-–∞–Ω–∞–ª–∏–∑–æ–º'
        )
        
    def export_kpi_summary(self):
        """–≠–∫—Å–ø–æ—Ä—Ç —Å–≤–æ–¥–∫–∏ KPI –º–µ—Ç—Ä–∏–∫"""
        query = """
        WITH kpi_calculations AS (
            SELECT 
                -- –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                COUNT(DISTINCT o.id) as total_orders,
                COUNT(DISTINCT CASE WHEN o.payment_status = 'paid' THEN o.id END) as paid_orders,
                COUNT(DISTINCT CASE WHEN o.status = 'delivered' THEN o.id END) as delivered_orders,
                COUNT(DISTINCT CASE WHEN o.status = 'cancelled' THEN o.id END) as cancelled_orders,
                COUNT(DISTINCT CASE WHEN o.status = 'returned' THEN o.id END) as returned_orders,
                
                -- –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                COALESCE(SUM(oi.quantity * oi.unit_price), 0) as gross_revenue,
                COALESCE(SUM(CASE WHEN o.payment_status = 'paid' THEN oi.quantity * oi.unit_price ELSE 0 END), 0) as net_paid_revenue,
                COALESCE(SUM(oi.quantity), 0) as total_units,
                
                -- –ö–ª–∏–µ–Ω—Ç—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏
                COUNT(DISTINCT o.customer_id) as unique_customers,
                COUNT(DISTINCT c.id) as total_customers,
                
                -- –¢–æ–≤–∞—Ä–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                COUNT(DISTINCT p.id) as total_products,
                COUNT(DISTINCT CASE WHEN p.is_active = true THEN p.id END) as active_products,
                
                -- –í—Ä–µ–º–µ–Ω–Ω–æ–π –ø–µ—Ä–∏–æ–¥
                MIN(o.order_date) as period_start,
                MAX(o.order_date) as period_end,
                CURRENT_DATE as report_date
                
            FROM orders o
            LEFT JOIN order_items oi ON o.id = oi.order_id
            LEFT JOIN customers c ON o.customer_id = c.id
            LEFT JOIN products p ON oi.product_id = p.id
        ),
        calculated_kpis AS (
            SELECT 
                *,
                -- AOV (—Å—Ä–µ–¥–Ω—è—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞–∫–∞–∑–∞)
                CASE 
                    WHEN paid_orders > 0 
                    THEN ROUND(net_paid_revenue / paid_orders, 2)
                    ELSE 0 
                END as aov,
                
                -- –ö–æ–Ω–≤–µ—Ä—Å–∏—è –æ–ø–ª–∞—Ç—ã
                CASE 
                    WHEN total_orders > 0 
                    THEN ROUND((paid_orders::numeric / total_orders::numeric) * 100, 2)
                    ELSE 0 
                END as payment_conversion_rate,
                
                -- –î–æ–ª—è –≤–æ–∑–≤—Ä–∞—Ç–æ–≤
                CASE 
                    WHEN total_orders > 0 
                    THEN ROUND((returned_orders::numeric / total_orders::numeric) * 100, 2)
                    ELSE 0 
                END as return_rate,
                
                -- –î–æ–ª—è –æ—Ç–º–µ–Ω
                CASE 
                    WHEN total_orders > 0 
                    THEN ROUND((cancelled_orders::numeric / total_orders::numeric) * 100, 2)
                    ELSE 0 
                END as cancellation_rate,
                
                -- –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –µ–¥–∏–Ω–∏—Ü –≤ –∑–∞–∫–∞–∑–µ
                CASE 
                    WHEN paid_orders > 0 
                    THEN ROUND(total_units::numeric / paid_orders::numeric, 1)
                    ELSE 0 
                END as avg_units_per_order,
                
                -- –ü—Ä–æ—Ü–µ–Ω—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
                CASE 
                    WHEN total_products > 0 
                    THEN ROUND((active_products::numeric / total_products::numeric) * 100, 2)
                    ELSE 0 
                END as active_products_rate
                
            FROM kpi_calculations
        )
        SELECT * FROM calculated_kpis
        """
        
        return self.export_table_to_formats(
            'kpi_summary',
            query,
            '–°–≤–æ–¥–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (KPI) –ø–æ –≤—Å–µ–º –¥–∞–Ω–Ω—ã–º'
        )
        
    def export_time_series_data(self):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤"""
        query = """
        WITH daily_metrics AS (
            SELECT 
                o.order_date,
                EXTRACT(YEAR FROM o.order_date) as year,
                EXTRACT(MONTH FROM o.order_date) as month,
                EXTRACT(DOW FROM o.order_date) as day_of_week,
                EXTRACT(WEEK FROM o.order_date) as week_of_year,
                
                -- –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                COUNT(*) as orders_count,
                COUNT(CASE WHEN o.payment_status = 'paid' THEN 1 END) as paid_orders,
                SUM(oi.quantity * oi.unit_price) as gross_revenue,
                SUM(CASE WHEN o.payment_status = 'paid' THEN oi.quantity * oi.unit_price ELSE 0 END) as net_revenue,
                SUM(oi.quantity) as units_sold,
                COUNT(DISTINCT o.customer_id) as unique_customers,
                
                -- –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ —Ç–∏–ø–∞–º –¥–Ω–µ–π
                CASE 
                    WHEN EXTRACT(DOW FROM o.order_date) IN (1,2,3,4,5) THEN 'weekday'
                    ELSE 'weekend'
                END as day_type,
                
                -- –°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å
                CASE 
                    WHEN EXTRACT(MONTH FROM o.order_date) IN (12,1,2) THEN 'winter'
                    WHEN EXTRACT(MONTH FROM o.order_date) IN (3,4,5) THEN 'spring'
                    WHEN EXTRACT(MONTH FROM o.order_date) IN (6,7,8) THEN 'summer'
                    ELSE 'autumn'
                END as season
                
            FROM orders o
            LEFT JOIN order_items oi ON o.id = oi.order_id
            WHERE o.order_date >= CURRENT_DATE - INTERVAL '2 years'
            GROUP BY o.order_date
        )
        SELECT 
            *,
            -- –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ (—Ç—Ä–µ–±—É–µ—Ç window functions)
            AVG(orders_count) OVER (ORDER BY order_date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) as orders_7day_avg,
            AVG(net_revenue) OVER (ORDER BY order_date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) as revenue_7day_avg,
            
            -- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º –¥–Ω–µ–º
            LAG(orders_count, 1) OVER (ORDER BY order_date) as prev_day_orders,
            LAG(net_revenue, 1) OVER (ORDER BY order_date) as prev_day_revenue
            
        FROM daily_metrics
        ORDER BY order_date DESC
        """
        
        return self.export_table_to_formats(
            'time_series_analytics',
            query,
            '–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã –º–µ—Ç—Ä–∏–∫ –ø–æ –¥–Ω—è–º –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤ –∏ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏'
        )
        
    def create_export_summary(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± —ç–∫—Å–ø–æ—Ä—Ç–µ"""
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±—â–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        self.export_manifest.update({
            'end_time': datetime.now().isoformat(),
            'total_tables_exported': len(self.export_manifest['exported_tables']),
            'total_records': sum(self.export_manifest['record_counts'].values()),
            'export_format': ['CSV', 'Parquet', 'JSON metadata'],
            'data_source': 'PostgreSQL Database',
            'data_timeframe': 'All available data',
            'data_quality': 'Cleaned and validated'
        })
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–∞–Ω–∏—Ñ–µ—Å—Ç–∞
        manifest_path = self.output_dir / 'export_manifest.json'
        with open(manifest_path, 'w', encoding='utf-8') as f:
            json.dump(self.export_manifest, f, ensure_ascii=False, indent=2, default=str)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ README –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        readme_content = f"""# –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

## –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

- **–î–∞—Ç–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞**: {self.export_manifest['export_timestamp']}
- **–í—Å–µ–≥–æ —Ç–∞–±–ª–∏—Ü**: {self.export_manifest['total_tables_exported']}
- **–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π**: {self.export_manifest['total_records']:,}
- **–§–æ—Ä–º–∞—Ç—ã**: CSV, Parquet, JSON –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ

## –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã

"""
        
        for table in self.export_manifest['exported_tables']:
            record_count = self.export_manifest['record_counts'].get(table, 0)
            file_sizes = self.export_manifest['file_sizes'].get(table, {})
            
            readme_content += f"""### {table}
- **–ó–∞–ø–∏—Å–µ–π**: {record_count:,}
- **CSV —Ä–∞–∑–º–µ—Ä**: {file_sizes.get('csv_mb', 0)} MB
- **Parquet —Ä–∞–∑–º–µ—Ä**: {file_sizes.get('parquet_mb', 0)} MB

"""
        
        readme_content += """## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤


exported_data/
‚îú‚îÄ‚îÄ csv/                    # CSV —Ñ–∞–π–ª—ã
‚îú‚îÄ‚îÄ parquet/               # Parquet —Ñ–∞–π–ª—ã  
‚îú‚îÄ‚îÄ json/                  # JSON –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
‚îú‚îÄ‚îÄ export_manifest.json  # –ú–∞–Ω–∏—Ñ–µ—Å—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞
‚îî‚îÄ‚îÄ README.md             # –≠—Ç–æ—Ç —Ñ–∞–π–ª
```

## –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### CSV —Ñ–∞–π–ª—ã
–ü–æ–¥—Ö–æ–¥—è—Ç –¥–ª—è:
- Excel –∏ Google Sheets
- –ü—Ä–æ—Å—Ç–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö
- –ò–º–ø–æ—Ä—Ç–∞ –≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤

### Parquet —Ñ–∞–π–ª—ã  
–ü–æ–¥—Ö–æ–¥—è—Ç –¥–ª—è:
- –ë–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
- Apache Spark, Pandas
- –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è

### JSON –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
–°–æ–¥–µ—Ä–∂–∞—Ç:
- –û–ø–∏—Å–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤
- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–∞–Ω–Ω—ã—Ö
- –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞—á–µ—Å—Ç–≤–µ
- –ü—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö

## –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö

–í—Å–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—à–ª–∏ –ø—Ä–æ—Ü–µ–¥—É—Ä—É –æ—á–∏—Å—Ç–∫–∏:
- ‚úÖ –£–¥–∞–ª–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã
- ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è  
- ‚úÖ –ü—Ä–æ–≤–µ—Ä–µ–Ω–∞ —Å—Å—ã–ª–æ—á–Ω–∞—è —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å
- ‚úÖ –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω—ã —Ñ–æ—Ä–º–∞—Ç—ã –¥–∞–Ω–Ω—ã—Ö

–ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞ÔøΩÔøΩ–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç—É–ø–Ω–∞ –≤ —Ñ–∞–π–ª–µ `docs/DATA_QUALITY_REPORT.md`.
"""
        
        readme_path = self.output_dir / 'README.md'
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(readme_content)
            
        logger.info(f"üìã –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞: {readme_path}")
        logger.info(f"üìã –ú–∞–Ω–∏—Ñ–µ—Å—Ç —Å–æ–∑–¥–∞–Ω: {manifest_path}")
        
    def run_export(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞"""
        try:
            logger.info("üöÄ –ù–ê–ß–ê–õ–û –≠–ö–°–ü–û–†–¢–ê –î–ê–ù–ù–´–•")
            logger.info("=" * 50)
            
            # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
            if not self.connect_db():
                return False
                
            # –°–ø–∏—Å–æ–∫ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º—ã—Ö —Ç–∞–±–ª–∏—Ü
            export_functions = [
                ("–ö–ª–∏–µ–Ω—Ç—ã —Å –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π", self.export_customers_data),
                ("–ó–∞–∫–∞–∑—ã —Å –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π", self.export_orders_data),
                ("–¢–æ–≤–∞—Ä—ã —Å –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π", self.export_products_data),
                ("–°–≤–æ–¥–∫–∞ KPI", self.export_kpi_summary),
                ("–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã", self.export_time_series_data)
            ]
            
            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —ç–∫—Å–ø–æ—Ä—Ç–∞
            successful_exports = 0
            for description, export_func in export_functions:
                logger.info(f"‚öôÔ∏è –≠–∫—Å–ø–æ—Ä—Ç: {description}")
                if export_func():
                    successful_exports += 1
                    logger.info(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ: {description}")
                else:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞: {description}")
                logger.info("-" * 30)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
            self.create_export_summary()
            
            # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            total_size_mb = sum(
                sum(sizes.values()) for sizes in self.export_manifest['file_sizes'].values()
            )
            
            logger.info("üéâ –≠–ö–°–ü–û–†–¢ –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û")
            logger.info("=" * 50)
            logger.info(f"üìä –£—Å–ø–µ—à–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {successful_exports}/{len(export_functions)} —Ç–∞–±–ª–∏—Ü")
            logger.info(f"üìÅ –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–æ–≤: {total_size_mb:.2f} MB")
            logger.info(f"üìã –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {sum(self.export_manifest['record_counts'].values()):,}")
            logger.info(f"üìÇ –ü–∞–ø–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {self.output_dir.absolute()}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –≠–ö–°–ü–û–†–¢–ê: {e}")
            return False
        finally:
            if hasattr(self, 'conn'):
                self.conn.close()
                logger.info("üîå –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î –∑–∞–∫—Ä—ã—Ç–æ")

if __name__ == "__main__":
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —Å timestamp
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_directory = f'exported_data_{timestamp}'
    
    # –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–æ—Ä—Ç–∞
    exporter = DataExporter(output_directory)
    success = exporter.run_export()
    
    if success:
        print(f"\nüéØ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ –ø–∞–ø–∫—É: {output_directory}")
        print("üìã –î–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–µ—Ç–∞–ª–µ–π —Å–º. —Ñ–∞–π–ª export_manifest.json")
    else:
        print("\n‚ùå –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–∞–º–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏.")
